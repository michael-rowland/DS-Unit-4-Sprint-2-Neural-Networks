{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "## Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: [Available Here](https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "df = pd.read_csv('churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN DATA\n",
    "df['gender'] = df['gender'].eq('Male').mul(1)\n",
    "\n",
    "def yes_no(text):\n",
    "    return 1 if text == 'Yes' else 0\n",
    "\n",
    "yes_no_cols = ['Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'Churn']\n",
    "for col in yes_no_cols:\n",
    "    df[col] = df[col].apply(yes_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODING\n",
    "ohc = ['InternetService', 'Contract', 'PaymentMethod']\n",
    "encoder = OneHotEncoder()\n",
    "encoded = encoder.fit_transform(df[ohc]).toarray()\n",
    "columns = encoder.get_feature_names(ohc)\n",
    "df_encoded = pd.DataFrame(encoded, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE DATAFRAMES\n",
    "df = df.drop(ohc, axis=1)\n",
    "df = df.drop(['customerID'], axis=1)\n",
    "df = pd.concat([df, df_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT AS NUMPY\n",
    "target = 'Churn'\n",
    "y = df[target].to_numpy()\n",
    "X = df.drop(target, axis=1)\n",
    "X['TotalCharges'] = X['TotalCharges'].replace(' ', 0.)\n",
    "X = X.astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "def create_model(optimizer='adam', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(26, input_dim=26, activation='relu'))\n",
    "    model.add(Dense(26, activation='relu'))\n",
    "    model.add(Dense(26, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mse', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "results = model.fit(X, y, epochs=20, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7043/7043 [==============================] - 0s 39us/sample - loss: 0.1158 - mse: 0.1158 - accuracy: 0.8369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11576873730023392, 0.11576871, 0.8368593]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(grid_result):\n",
    "    print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER TUNING, MUST USE GRID SEARCH AND CROSS VALIDATION\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "stop = EarlyStopping(monitor='accuracy', min_delta=0.001, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7949739694595337 using {'batch_size': 100, 'epochs': 20}\n",
      "Means: 0.7802069783210754, Stdev: 0.00594349978026747 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.7843254804611206, Stdev: 0.003445340237015599 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.7884420355161031, Stdev: 0.003541267201158549 with: {'batch_size': 40, 'epochs': 20}\n",
      "Means: 0.7946901321411133, Stdev: 0.00205129291787358 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.7925598621368408, Stdev: 0.002183593514392557 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.7949739694595337, Stdev: 0.0025898276908970287 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# BATCH SIZE\n",
    "model = KerasClassifier(build_fn=create_model, verbose=False)\n",
    "parameters = {\n",
    "    'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "    'epochs': [20]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=1,\n",
    "    cv=3\n",
    ")\n",
    "grid_result = grid.fit(X, y, callbacks=[stop])\n",
    "print_results(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.26537078619003296 using {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.26537078619003296, Stdev: 0.004601538989727422 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.26537078619003296, Stdev: 0.004601538989727422 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.26537078619003296, Stdev: 0.004601538989727422 with: {'batch_size': 40, 'epochs': 20}\n",
      "Means: 0.26537078619003296, Stdev: 0.004601538989727422 with: {'batch_size': 60, 'epochs': 20}\n",
      "Means: 0.26537078619003296, Stdev: 0.004601538989727422 with: {'batch_size': 80, 'epochs': 20}\n",
      "Means: 0.26537078619003296, Stdev: 0.004601538989727422 with: {'batch_size': 100, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# EPOCHS\n",
    "model = KerasClassifier(build_fn=create_model, verbose=False)\n",
    "parameters = {\n",
    "    'batch_size': [10],\n",
    "    'epochs': [5, 10, 20, 30, 40, 50]\n",
    "}\n",
    "grid_result = grid.fit(X, y, callbacks=[stop])\n",
    "print_results(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7973870237668356 using {'batch_size': 10, 'epochs': 20, 'optimizer': 'sgd'}\n",
      "Means: 0.7802066802978516, Stdev: 0.003907393050319533 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'adam'}\n",
      "Means: 0.7789284586906433, Stdev: 0.00877427163311916 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'nadam'}\n",
      "Means: 0.7973870237668356, Stdev: 0.0023548223398968332 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'sgd'}\n",
      "Means: 0.6564104159673055, Stdev: 0.0697960940020746 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'adadelta'}\n",
      "Means: 0.7854603926340739, Stdev: 0.0021578498765298898 with: {'batch_size': 10, 'epochs': 20, 'optimizer': 'adagrad'}\n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZER\n",
    "model = KerasClassifier(build_fn=create_model, verbose=False)\n",
    "parameters = {\n",
    "    'batch_size': [10],\n",
    "    'optimizer': ['adam', 'nadam', 'sgd', 'adadelta', 'adagrad'],\n",
    "    'epochs':[20]\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=1,\n",
    "    cv=3\n",
    ")\n",
    "grid_result = grid.fit(X, y, callbacks=[stop])\n",
    "print_results(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.799659013748169 using {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Means: 0.799659013748169, Stdev: 0.0019388835439777708 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'optimizer': 'sgd'}\n",
      "Means: 0.7961095174153646, Stdev: 0.0005628553981703821 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.01, 'optimizer': 'sgd'}\n",
      "Means: 0.7971039414405823, Stdev: 0.002576133387160183 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.1, 'optimizer': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "# LEARNING RATE\n",
    "model = KerasClassifier(build_fn=create_model, verbose=False)\n",
    "parameters = {\n",
    "    'batch_size': [10],\n",
    "    'epochs':[20],\n",
    "    'optimizer': ['sgd'],\n",
    "    'learning_rate': [0.001, 0.01, 0.1]\n",
    "\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=1,\n",
    "    cv=3\n",
    ")\n",
    "grid_result = grid.fit(X, y, callbacks=[stop])\n",
    "print_results(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7706962625185648 using {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n",
      "Means: 0.7346291939417521, Stdev: 0.004601525031331852 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.0}\n",
      "Means: 0.744992713133494, Stdev: 0.01619429611592491 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.01}\n",
      "Means: 0.7706962625185648, Stdev: 0.020058926012406053 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n",
      "Means: 0.7652935981750488, Stdev: 0.026420731922726974 with: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.05}\n"
     ]
    }
   ],
   "source": [
    "# MOMENTUM\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# MODEL\n",
    "def create_model(momentum=0.0, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(26, input_dim=26, activation='relu'))\n",
    "    model.add(Dense(26, activation='relu'))\n",
    "    model.add(Dense(26, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mse', optimizer=SGD(learning_rate=learning_rate, momentum=momentum), metrics=['mse', 'accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=False)\n",
    "\n",
    "parameters = {\n",
    "    'batch_size': [10],\n",
    "    'epochs':[20],\n",
    "    'learning_rate': [0.001],\n",
    "    'momentum': [0.0, 0.01, 0.02, 0.05]\n",
    "\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=1,\n",
    "    cv=3\n",
    ")\n",
    "grid_result = grid.fit(X, y, callbacks=[stop])\n",
    "print_results(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7824799418449402 using {'activation_fxn': 'relu', 'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n",
      "Means: 0.7824799418449402, Stdev: 0.004707336098485002 with: {'activation_fxn': 'relu', 'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n",
      "Means: 0.7346291939417521, Stdev: 0.004601525031331852 with: {'activation_fxn': 'sigmoid', 'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n",
      "Means: 0.7346291939417521, Stdev: 0.004601525031331852 with: {'activation_fxn': 'softmax', 'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n"
     ]
    }
   ],
   "source": [
    "# ACTIVATION FUNCTIONS\n",
    "\n",
    "def create_model(momentum=0.0, learning_rate=0.001, add_layers=1, activation_fxn='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(26, input_dim=26, activation=activation_fxn))\n",
    "    for layer in range(add_layers):\n",
    "        model.add(Dense(26, activation=activation_fxn))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mse', optimizer=SGD(learning_rate=learning_rate, momentum=momentum), metrics=['mse', 'accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=False)\n",
    "\n",
    "parameters = {\n",
    "    'batch_size': [10],\n",
    "    'epochs':[20],\n",
    "    'learning_rate': [0.001],\n",
    "    'momentum': [0.02],\n",
    "    'activation_fxn': ['relu', 'sigmoid', 'softmax']\n",
    "\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=1,\n",
    "    cv=3\n",
    ")\n",
    "grid_result = grid.fit(X, y, callbacks=[stop])\n",
    "print_results(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7718306581179301 using {'activation_fxn': 'relu', 'add_layers': 1, 'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n",
      "Means: 0.7718306581179301, Stdev: 0.0037230276835275387 with: {'activation_fxn': 'relu', 'add_layers': 1, 'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n",
      "Means: 0.7346293330192566, Stdev: 0.003973197106041736 with: {'activation_fxn': 'relu', 'add_layers': 2, 'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n",
      "Means: 0.7346291939417521, Stdev: 0.004601525031331852 with: {'activation_fxn': 'relu', 'add_layers': 3, 'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n",
      "Means: 0.7346291939417521, Stdev: 0.004601525031331852 with: {'activation_fxn': 'relu', 'add_layers': 4, 'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n",
      "Means: 0.7346291939417521, Stdev: 0.004601525031331852 with: {'activation_fxn': 'relu', 'add_layers': 5, 'batch_size': 10, 'epochs': 20, 'learning_rate': 0.001, 'momentum': 0.02}\n"
     ]
    }
   ],
   "source": [
    "# NUMBER OF LAYERS\n",
    "model = KerasClassifier(build_fn=create_model, verbose=False)\n",
    "\n",
    "parameters = {\n",
    "    'batch_size': [10],\n",
    "    'epochs':[20],\n",
    "    'learning_rate': [0.001],\n",
    "    'momentum': [0.02],\n",
    "    'activation_fxn': ['relu'],\n",
    "    'add_layers': [1, 2, 3, 4, 5]\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=parameters,\n",
    "    n_jobs=1,\n",
    "    cv=3\n",
    ")\n",
    "grid_result = grid.fit(X, y, callbacks=[stop])\n",
    "print_results(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPOUT REGULARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER OF NEURONS IN HIDDEN LAYER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "4-2",
   "language": "python",
   "name": "4-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
